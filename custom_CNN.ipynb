{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom CNN to show how YOLOv5 works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import imageio\n",
    "import keras\n",
    "import random\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Activation, Dropout\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Shuffle the images and labels\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# img_files = [f for f in os.listdir(\"data/images/\") if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "# label_files = [f.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\") for f in img_files]\n",
    "\n",
    "# img_label_pairs = list(zip(img_files, label_files))\n",
    "\n",
    "# random.shuffle(img_label_pairs)\n",
    "\n",
    "# if not os.path.exists(\"shuffled_data/images\"):\n",
    "#     os.makedirs(\"shuffled_data/images\")\n",
    "# if not os.path.exists(\"shuffled_data/labels\"):\n",
    "#     os.makedirs(\"shuffled_data/labels\")\n",
    "\n",
    "# for i, (img, label) in enumerate(img_label_pairs):\n",
    "#     shutil.copy2(\"data/images/\" + img, \"shuffled_data/images/img_{}.jpg\".format(i))\n",
    "#     shutil.copy2(\"data/labels/\" + label, \"shuffled_data/labels/img_{}.txt\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split the shuffled dataset into training and validation images\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# images = os.listdir(\"shuffled_data/images\")\n",
    "# labels = os.listdir(\"shuffled_data/labels\")\n",
    "\n",
    "# images_train, images_val, labels_train, labels_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create the training and validation folders if they don't already exist\n",
    "# if not os.path.exists(\"shuffled_data/train\"):\n",
    "#     os.makedirs(\"shuffled_data/train/images\")\n",
    "#     os.makedirs(\"shuffled_data/train/labels\")\n",
    "\n",
    "# if not os.path.exists(\"shuffled_data/valid\"):\n",
    "#     os.makedirs(\"shuffled_data/valid/images\")\n",
    "#     os.makedirs(\"shuffled_data/valid/labels\")\n",
    "\n",
    "# # Copy the training images and labels to the training folder\n",
    "# for image, label in zip(images_train, labels_train):\n",
    "#     shutil.copy2(f\"shuffled_data/images/{image}\", \"shuffled_data/train/images/\")\n",
    "#     shutil.copy2(f\"shuffled_data/labels/{label}\", \"shuffled_data/train/labels/\")\n",
    "\n",
    "# # Copy the validation images and labels to the validation folder\n",
    "# for image, label in zip(images_val, labels_val):\n",
    "#     shutil.copy2(f\"shuffled_data/images/{image}\", \"shuffled_data/valid/images/\")\n",
    "#     shutil.copy2(f\"shuffled_data/labels/{label}\", \"shuffled_data/valid/labels/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get the shape of the training and validation images to confirm correct size\n",
    "Expected output: (747, 187)\n",
    "\"\"\"\n",
    "\n",
    "train_path =  \"shuffled_data/train/images\"\n",
    "valid_path =  \"shuffled_data/valid/images\"\n",
    "\n",
    "def get_shape(train_path, valid_path):\n",
    "    train_size = len([f for f in os.listdir(train_path) if f.endswith('.jpg')])\n",
    "    val_size = len([f for f in os.listdir(valid_path) if f.endswith('.jpg')])\n",
    "\n",
    "\n",
    "    return train_size, val_size\n",
    "\n",
    "get_shape(train_path, valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualise the labels on random images\n",
    "\"\"\"\n",
    "\n",
    "# Change coords from 0-1 to pixle location. Label files in the format (name, xc, yc, w, h)\n",
    "def denormalize_coords(xc, yc, w, h, image_width, image_height):\n",
    "    x1 = int((xc - w / 2) * image_width)\n",
    "    y1 = int((yc - h / 2) * image_height)\n",
    "    x2 = int((xc + w / 2) * image_width)\n",
    "    y2 = int((yc + h / 2) * image_height)\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "# Show the bounding box by plotting a cv2 rectangle at the denormalized coords\n",
    "def display_bbox(image_names):\n",
    "    for image_name in image_names:\n",
    "        image_path = \"shuffled_data/train/images/{}\".format(image_name.replace('.txt', '.jpg'))\n",
    "        label_path = \"shuffled_data/train/labels/{}\".format(image_name)\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        image_height, image_width, _ = image.shape\n",
    "\n",
    "        with open(label_path, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            class_name, xc, yc, w, h = line.strip().split(' ')\n",
    "\n",
    "            x1, y1, x2, y2 = denormalize_coords(float(xc), float(yc), float(w), float(h), image_width, image_height)\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), (150, 150, 0), 2)\n",
    "            cv2.putText(image, class_name, (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 1, (150, 150, 0), 2, cv2.LINE_AA)\n",
    "            print(\"Normalized points: \", xc, yc, w, h)\n",
    "            print(\"Denormalized points: \", x1, y1, x2, y2)\n",
    "            \n",
    "        # save output images to /output_images/\n",
    "        cv2.imwrite(\"output_images/{}.jpg\".format(image_name), image)\n",
    "        display(Image(\"output_images/{}.jpg\".format(image_name)))\n",
    "\n",
    "\n",
    "image_names = [f for f in os.listdir(\"shuffled_data/train/labels/\") if f.endswith(\".txt\")]\n",
    "random_image_names = random.sample(image_names, 3)\n",
    "\n",
    "display_bbox(random_image_names)\n",
    "print(random_image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the images and labels as an np.array to be used in the model\n",
    "    Expected train size: (747, 416, 416, 3) \n",
    "    Expected valid size: (187, 416, 416, 3)\n",
    "    Expected names size: 24\n",
    "\"\"\"\n",
    "\n",
    "def get_images(path):\n",
    "    images = []\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            image = imageio.imread(os.path.join(path, filename))\n",
    "            images.append(image)\n",
    "    return np.array(images)\n",
    "\n",
    "def get_labels(path):\n",
    "    labels = []\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(path, filename), 'r') as f:\n",
    "                name, xc, yc, x1, y1 = f.read().strip().split()\n",
    "                labels.append(name)\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(labels)\n",
    "    one_hot_labels = to_categorical(label_encoder.transform(labels))\n",
    "    return one_hot_labels\n",
    "\n",
    "def get_names(path):\n",
    "    integers = []\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(path, filename), 'r') as f:\n",
    "                integer = int(f.read().strip().split()[0])\n",
    "                integers.append(integer)\n",
    "    unique_name = set(integers)\n",
    "    return len(unique_name)\n",
    "\n",
    "\n",
    "train_images_path = \"shuffled_data/train/images\"\n",
    "train_labels_path = \"shuffled_data/train/labels\"\n",
    "valid_images_path = \"shuffled_data/valid/images\"\n",
    "valid_labels_path = \"shuffled_data/valid/labels\"\n",
    "\n",
    "x_train = get_images(train_images_path)\n",
    "y_train = get_labels(train_labels_path)\n",
    "x_val = get_images(valid_images_path)\n",
    "y_val = get_labels(valid_labels_path)\n",
    "num_classes = get_names(train_labels_path)\n",
    "\n",
    "print(\"Train image size: \", x_train.shape, \"\\nTrain label size: \", x_train.shape)\n",
    "print(\"\\n\\nValid image size: \", x_val.shape, \"\\nValid label size: \", x_val.shape)\n",
    "print(\"\\n\\nClasses in dataset set: \", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Four layer CNN\n",
    "Adam Optimizer\n",
    "Binary Crossentropy with Logits Loss Function\n",
    "Swish activation function\n",
    "    Swish = x * sigmoid(x)\n",
    "    Sigmoid = 1 / 1 + exp(-x)\n",
    "\"\"\"\n",
    "\n",
    "num_of_epochs, rr, dropout, lr, init_loss = 20, 0.1, 0.5, 0.01, 1\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "\n",
    "def swish(x):\n",
    "    return x * keras.activations.sigmoid(x)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first convolutional layer\n",
    "model.add(Conv2D(32, (3,3), input_shape=(416, 416, 3)))\n",
    "model.add(Activation(swish))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Add the second convolutional layer\n",
    "model.add(Conv2D(64, (3,3)))   \n",
    "model.add(Activation(swish))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Add the third convolutional layer\n",
    "model.add(Conv2D(128, (3,3)))\n",
    "model.add(Activation(swish))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Add the fourth convolutional layer\n",
    "model.add(Conv2D(128, (3,3)))\n",
    "model.add(Activation(swish))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Flatten the output from the convolutional layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add the fully connected layer\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(swish))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(num_classes, activation=None))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, batch_size=16, epochs=num_of_epochs, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To display the number of layers, parameters, abd gradients of the model\n",
    "Warnings about large numbers are disabled\n",
    "\"\"\"\n",
    "import warnings\n",
    "\n",
    "def display_model_info(model):\n",
    "    num_layers = len(model.layers)\n",
    "    num_params = model.count_params()\n",
    "    trainable_params = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        num_gradients = trainable_params * num_classes * num_of_epochs\n",
    "    print(f\"Model Summary: {num_layers} layers, {num_params} parameters, {num_gradients} gradients\")\n",
    "\n",
    "display_model_info(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generates a confusion matrix based off the model\n",
    "\"\"\"\n",
    "# Generate predictions on the validation data\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "# Convert the predictions into binary class labels\n",
    "y_pred_class = np.round(y_pred)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val.argmax(axis=1), y_pred_class.argmax(axis=1))\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plots the models accuracy and loss\n",
    "\"\"\"\n",
    "\n",
    "def plot_loss_accuracy(history):\n",
    "\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    train_acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    ax1.plot(train_loss, label='Training Loss')\n",
    "    ax1.plot(val_loss, label='Validation Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(train_acc, label='Training Accuracy')\n",
    "    ax2.plot(val_acc, label='Validation Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"shuffled_data/train/images/img_921.jpg\"\n",
    "\n",
    "image = cv2.imread(test_path)\n",
    "image = cv2.resize(image, (416, 416))\n",
    "image = np.array(image)\n",
    "image = image / 255.0\n",
    "\n",
    "\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n",
    "# Make a prediction\n",
    "prediction = model.predict(image)\n",
    "\n",
    "# Print the predicted class\n",
    "predicted_class = np.argmax(prediction)\n",
    "print(f\"The predicted class is {predicted_class}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a322872bde48165c8b38fc07aafe23838cb691b5065cdeed8882e01b10b50872"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
